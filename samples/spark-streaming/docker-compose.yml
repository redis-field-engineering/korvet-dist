services:
  # Redis - Backend storage for Korvet
  redis:
    image: redis
    ports:
      - "6379:6379"

  # Korvet Server - Kafka-compatible streaming service
  korvet:
    image: redisfield/korvet
    ports:
      - "9092:9092"
    environment:
      - KORVET_REDIS_HOST=redis
      - KORVET_SERVER_ADVERTISED_HOST=korvet
    depends_on:
      - redis

  # Spark Master
  spark-master:
    image: apache/spark:3.5.0
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.master.Master
    environment:
      - SPARK_NO_DAEMONIZE=true
    ports:
      - "8081:8080"  # Spark Master Web UI
      - "7077:7077"  # Spark Master port
      - "4040:4040"  # Spark Application UI (when running spark-submit)
    volumes:
      - ./streaming_reader.py:/opt/spark-apps/streaming_reader.py
      - ./data:/opt/spark-data
      - spark-ivy-cache:/home/spark/.ivy2

  # Spark Worker
  spark-worker:
    image: apache/spark:3.5.0
    command: /opt/spark/bin/spark-class org.apache.spark.deploy.worker.Worker spark://spark-master:7077
    environment:
      - SPARK_NO_DAEMONIZE=true
      - SPARK_WORKER_MEMORY=1G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    volumes:
      - ./streaming_reader.py:/opt/spark-apps/streaming_reader.py
      - ./data:/opt/spark-data

  # Data Generator - Produces sample events to Korvet
  data-generator:
    image: apache/kafka
    depends_on:
      - korvet
    volumes:
      - ./generate-data.sh:/generate-data.sh
    entrypoint: ["/bin/bash", "/generate-data.sh"]
    environment:
      - KAFKA_BOOTSTRAP_SERVERS=korvet:9092

volumes:
  spark-ivy-cache:
