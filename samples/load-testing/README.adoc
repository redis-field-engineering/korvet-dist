= Korvet Load Testing Sample
:toc:
:icons: font

== Overview

This sample demonstrates various approaches to load testing Korvet using industry-standard Kafka benchmarking tools.

**Includes:**

* Redis backend storage
* Korvet server with Kafka protocol
* Kafka's built-in performance testing tools (`kafka-producer-perf-test`, `kafka-consumer-perf-test`)
* Pre-configured test scenarios via Makefile
* Prometheus + Grafana for real-time metrics visualization

**Use Cases:**

* Performance benchmarking
* Capacity planning
* Stress testing
* Regression testing
* Comparing Korvet vs native Kafka performance

**Demo time:** 10-15 minutes

== Prerequisites

* Docker 20.10+
* Docker Compose 2.0+
* At least 4GB available memory
* (Optional) Go 1.21+ for building custom tools

== Quick Start

[source,bash]
----
cd load-testing
make up          # Start Korvet, Redis, Prometheus, Grafana
make test-basic  # Run basic performance test
make dashboard   # Open Grafana dashboard
----

== Available Tests

All tests use Kafka's standard performance testing tools (`kafka-producer-perf-test` and `kafka-consumer-perf-test`).

=== Basic Tests

**Producer Performance Test:**

[source,bash]
----
make test-producer
----

Produces 100K messages (1KB each) at 10K msg/sec target throughput.

**Consumer Performance Test:**

[source,bash]
----
make test-consumer
----

Consumes all messages from the `perf-test` topic with detailed statistics.

**Basic End-to-End Test:**

[source,bash]
----
make test-basic
----

Quick test producing and consuming 10K messages to verify everything works.

**Concurrent Producer/Consumer Test:**

[source,bash]
----
make test-concurrent
----

Runs producer and consumer simultaneously to test steady-state performance (5M messages at 50K msg/sec).

=== Load Test Scenarios

**Load Test (Recommended):**

[source,bash]
----
make test-load
----

Configuration: 10M messages, 1KB size, unlimited throughput

**Baseline Performance:**

[source,bash]
----
make test-baseline
----

Configuration: 1M messages, 1KB size, 10K msg/sec target

**High Throughput Stress Test:**

[source,bash]
----
make test-high-throughput
----

Configuration: 50M messages, 1KB size, unlimited throughput

**Large Messages:**

[source,bash]
----
make test-large-messages
----

Configuration: 100K messages, 100KB size, unlimited throughput

**Consumer Group Performance:**

[source,bash]
----
make test-consumer-group
----

Configuration: 100K messages with 4 concurrent consumers

**Sustained Load:**

[source,bash]
----
make test-sustained
----

Configuration: 30 minutes at 10K msg/sec (18M total messages)

**Run All Tests:**

[source,bash]
----
make test-all
----

Runs all test scenarios sequentially.

== Monitoring and Metrics

=== View Real-Time Metrics

**Grafana Dashboard:**

[source,bash]
----
make dashboard
----

Opens http://localhost:3000 with pre-configured dashboard showing:

* Throughput (messages/sec, MB/sec)
* Latency (p50, p95, p99, p999)
* Error rates
* Consumer lag
* JVM metrics
* Redis metrics

**Prometheus Metrics:**

[source,bash]
----
make metrics
----

Opens http://localhost:9090 for raw metrics exploration.

=== Key Metrics to Monitor

**Producer Metrics:**
* `korvet_produce_messages_total` - Total messages produced
* `korvet_produce_bytes_total` - Total bytes produced
* `korvet_produce_latency_seconds` - Producer latency histogram

**Consumer Metrics:**
* `korvet_fetch_messages_total` - Total messages fetched
* `korvet_fetch_bytes_total` - Total bytes fetched
* `korvet_fetch_latency_seconds` - Consumer latency histogram

**Redis Metrics:**
* `lettuce_command_completion_seconds` - Redis command latency
* `lettuce_command_active_connections` - Active Redis connections

**JVM Metrics:**
* `jvm_memory_used_bytes` - JVM memory usage
* `jvm_gc_pause_seconds` - GC pause times
* `process_cpu_usage` - CPU usage

== Interpreting Results

=== Throughput

**Good Performance:**
* Producer: >10,000 msg/sec for 1KB messages
* Consumer: >15,000 msg/sec for 1KB messages

**Factors Affecting Throughput:**
* Message size (larger = lower msg/sec, but higher MB/sec)
* Number of partitions (more = higher throughput)
* Batch size (larger = higher throughput)
* Compression (enabled = lower throughput, less storage)

=== Latency

**Good Performance:**
* p50: <10ms
* p95: <50ms
* p99: <100ms
* p999: <500ms

**Factors Affecting Latency:**
* Network latency to Redis
* Redis performance
* Message size
* System load

=== Resource Usage

**Typical Resource Usage:**
* CPU: 1-2 cores at 10,000 msg/sec
* Memory: 512MB-1GB heap
* Redis memory: ~1KB per message (depends on retention)



== Advanced Configuration

=== Tuning Korvet for Performance

Edit `docker-compose.yml` to adjust Korvet settings:

[source,yaml]
----
korvet:
  environment:
    # JVM thread count (default: 250, async version uses 50)
    BPL_JVM_THREAD_COUNT: 50

    # JVM memory settings
    JAVA_TOOL_OPTIONS: -XX:MaxDirectMemorySize=512m

    # Enable Redis metrics
    KORVET_REDIS_METRICS_ENABLED: true
    KORVET_REDIS_METRICS_HISTOGRAM: true
  mem_limit: 2g
----

== Troubleshooting

=== Low Throughput

**Check:**
1. Redis performance: `docker compose exec redis redis-cli INFO stats`
2. Network latency: `docker compose exec kafka-tools ping redis`
3. CPU usage: `docker stats`
4. Korvet logs: `docker compose logs korvet`

**Solutions:**
* Increase worker threads
* Increase Redis pool size
* Use multiple partitions
* Increase batch size

=== High Latency

**Check:**
1. Redis latency: `docker compose exec redis redis-cli --latency`
2. Network issues: `docker compose exec kafka-tools ping korvet`
3. GC pauses: Check Korvet logs for GC events

**Solutions:**
* Tune JVM GC settings
* Reduce message size
* Optimize Redis configuration
* Check system resources

=== Out of Memory

**Solutions:**
* Increase JVM heap: `-Xmx2g`
* Configure Redis maxmemory
* Reduce message retention
* Use compression

== Cleanup

[source,bash]
----
# Stop all services
make down

# Remove all data
make clean
----

== Example Results

Here are typical results from a MacBook Pro (M1, 16GB RAM):

**Baseline Test (1KB messages):**
----
Throughput: 12,500 msg/sec (12.2 MB/sec)
Latency p50: 8ms, p95: 25ms, p99: 45ms
CPU: 1.5 cores, Memory: 800MB
----

**High Throughput Test (unlimited):**
----
Throughput: 45,000 msg/sec (43.9 MB/sec)
Latency p50: 15ms, p95: 85ms, p99: 150ms
CPU: 3.2 cores, Memory: 1.2GB
----

**Large Messages (100KB):**
----
Throughput: 850 msg/sec (83 MB/sec)
Latency p50: 120ms, p95: 250ms, p99: 400ms
CPU: 2.1 cores, Memory: 1.5GB
----

== Next Steps

* Try different message sizes and throughput targets
* Experiment with multiple partitions
* Test consumer group behavior
* Compare with native Kafka
* Integrate into CI/CD pipeline
* Create custom test scenarios with k6

== See Also

* link:../kafka-cli/README.adoc[Kafka CLI Tools Demo]
* link:../../observability/README.adoc[Observability Setup]
* link:../../README.adoc[Korvet Project README]
